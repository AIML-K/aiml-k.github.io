---
title: 'Position: Solve Layerwise Linear Models First to Understand Neural Dynamical Phenomena (Neural Collapse, Emergence, Lazy/Rich Regime, and Grokking)'

event: AIML@K Seminar Series
event_url: https://aiml-k.github.io/tag/seminar/  
tags: ['seminar']

location: Room 526, Asan Science Building 
address:
  street: 145 Anam-ro
  city: Seongbuk-gu, Seoul
  # region: CA
  postcode: '02841'
  country: South Korea

summary: 'Can layerwise linear models simplify complex neural network dynamics speed up deep learning research?'
abstract: |
  In physics, complex systems are often simplified into minimal, solvable models that retain only the core principles. In machine learning, layerwise linear models (e.g., linear neural networks) act as simplified representations of neural network dynamics. These models follow the dynamical feedback principle, which describes how layers mutually govern and amplify each other's evolution. This principle extends beyond the simplified models, successfully explaining a wide range of dynamical phenomena in deep neural networks, including neural collapse, emergence, lazy and rich regimes, and grokking. In this position paper, we call for the use of layerwise linear models retaining the core principles of neural dynamical phenomena to accelerate the science of deep learning.

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: '2025-07-04T14:00:00+09:00'
date_end: '2025-07-04T15:00:00+09:00'
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: '2024-06-23T00:00:00Z'

authors: ['Yoonsoo Nam']

# Is this a featured talk? (true/false)
featured: false

image:
  caption: 'This talk is a preview of **[an ICML 2025 position paper presentation](https://icml.cc/virtual/2025/poster/40104)**'
#   focal_point: Right

url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''

links:
- name: ICML
  url: https://icml.cc/virtual/2025/poster/40104
- name: ArXiv
  url: https://arxiv.org/abs/2502.21009


# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides:

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
---

We are excited to see the talk one week in advance!  If you seek for more detail, please refer to [the ArXiv link](https://arxiv.org/abs/2502.21009).

Also, note that 
- the speaker has also authored another paper in NeurIPS 2024 which was the topic of **[a recent talk](https://aiml-k.github.io/event/25-06-17-seokhyeonglee-neurips2024/)**.
- speakers from two recent talks ([one](https://aiml-k.github.io/event/25-06-17-seokhyeonglee-neurips2024/), [two](https://aiml-k.github.io/event/25-06-27-yechanpark-autoformalization/)) are co-authors of this ICML 2025 position paper.  

<!-- 
Slides can be added in a few ways:

- **Create** slides using Wowchemy's [_Slides_](https://docs.hugoblox.com/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://docs.hugoblox.com/writing-markdown-latex/).

Further event details, including page elements such as image galleries, can be added to the body of this page. -->
