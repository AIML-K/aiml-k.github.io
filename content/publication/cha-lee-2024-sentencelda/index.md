---
title: 'SentenceLDA: Discriminative and Robust Document Representation with Sentence
  Level Topic Model'
authors:
- taehuncha
- admin
date: '2024-03-01'
publishDate: '2024-03-24T05:32:51.489481Z'
publication_types:
- paper-conference
publication: '*Proceedings of the 18th Conference of the European Chapter of the Association
  for Computational Linguistics (Volume 1: Long Papers)*'
publication_short: In *EACL 2024*

abstract: A subtle difference in context results in totally different nuances even
  for lexically identical words. On the other hand, two words can convey similar meanings
  given a homogeneous context. As a result, considering only word spelling information
  is not sufficient to obtain quality text representation. We propose SentenceLDA,
  a sentence-level topic model. We combine modern SentenceBERT and classical LDA to
  extend the semantic unit from word to sentence. By extending the semantic unit,
  we verify that SentenceLDA returns more discriminative document representation than
  other topic models, while maintaining LDA′s elegant probabilistic interpretability.
  We also verify the robustness of SentenceLDA by comparing the inference results
  on original and paraphrased texts. Additionally, we implement one possible application
  of SentenceLDA on corpus-level key opinion mining by applying SentenceLDA on an
  argumentative corpus, DebateSum.
links:
- name: URL
  url: https://aclanthology.org/2024.eacl-long.31
url_pdf: 'https://aclanthology.org/2024.eacl-long.31.pdf'

tags: ['NLP']

image:
  caption: 'Taehun Cha presenting the work at EACL 2024 (St. Julian’s, Malta)'
  focal_point: ''
  preview_only: false

---
